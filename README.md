# Rectified Flow

This repository contains an implementation of Rectified Flows for generative modeling, allowing for multi-stage training and distillation.

## Table of Contents
- [Rectified Flow](#rectified-flow)
  - [Table of Contents](#table-of-contents)
  - [Project Structure](#project-structure)
  - [Setup](#setup)
  - [Training](#training)
  - [Evaluation (FID)](#evaluation-fid)
  - [Visualization](#visualization)
  - [Configuration](#configuration)

## Project Structure

```
.
├── config.py                 # Global configuration settings
├── constants.py              # Defines constants used across the project
├── evaluate_fid.py           # Script to evaluate FID score of trained models
├── requirements.txt          # Python dependencies
├── setup_env.sh              # Script to set up the Python virtual environment
├── train.py                  # Main training script for multi-stage rectified flows
├── visualize_generations.py  # Script to visualize generated images
├── data/                     # Dataset storage (e.g., CIFAR-10, MNIST)
├── data_utils/               # Utilities for data generation and loading
│   ├── data_generator.py
│   └── datasets.py
├── evaluation/               # FID calculation utilities
│   └── fid.py
├── experiments/              # Directory for saving experiment results (models, images, configs, logs)
├── generation/               # Image generation logic
│   └── generators.py
├── models/                   # Neural network architectures (Unet, MobileResUNet)
│   ├── __init__.py
│   ├── improved_unet.py
│   ├── mobile_res_unet.py
│   └── unet.py
└── training/                 # Training-related modules (loss functions, samplers, trainer)
    ├── loss.py
    ├── sampler.py
    └── trainer.py
```

## Setup

To set up the project, you need to create a Python virtual environment and install the required dependencies.

```bash
# Create and activate the virtual environment, then install dependencies
./setup_env.sh
```

This script will:
1.  Create a virtual environment named `venv`.
2.  Activate the virtual environment.
3.  Install all packages listed in `requirements.txt`.

## Training

The `train.py` script is used to train the rectified flow models across multiple stages:

*   **Stage 1 (1-Rectified Flow):** Trains the initial rectified flow model from noise to data.
*   **Stage 2 (2-Rectified Flow / Reflow):** Refines the flow by training a second rectified flow on data generated from the Stage 1 model, aiming to reduce NFEs.
*   **Stage 3 (Distillation):** Distills the knowledge from the multi-step 2-rectified flow into a single-step model for faster generation.

To start training, run:

```bash
python train.py
```

Training parameters and configurations are managed in `config.py`. The script will save models, generated images, configurations, and logs in the `experiments/` directory.

## Evaluation (FID)

You can evaluate the Fréchet Inception Distance (FID) score of a trained model using `evaluate_fid.py`.

```bash
python evaluate_fid.py --model_path <path_to_model_checkpoint> --config_path <path_to_config.json> --steps <num_generation_steps> --stage <training_stage>
```

**Arguments:**
*   `--model_path`: Path to the trained model checkpoint (e.g., `experiments/MNIST/exp_030/models/stage1_epoch_200.pth`).
*   `--config_path`: Path to the `config.json` file corresponding to the experiment (e.g., `experiments/MNIST/exp_030/configs/config.json`).
*   `--steps`: Number of generation steps to use for FID calculation.
*   `--stage`: The training stage of the model (1, 2, or 3).

## Visualization

To visualize images generated by a trained model, use `visualize_generations.py`.

```bash
python visualize_generations.py --model_path <path_to_model_checkpoint> --config_path <path_to_config.json> --steps <num_generation_steps> --stage <training_stage>
```

**Arguments:**
*   `--model_path`: Path to the trained model checkpoint.
*   `--config_path`: Path to the `config.json` file for the experiment.
*   `--steps`: Number of generation steps to use for visualization.
*   `--stage`: The training stage of the model (1, 2, or 3).

## Configuration

The `config.py` file contains all the configurable parameters for training, including:
*   `dataset`: Dataset to use (e.g., `MNIST`, `CIFAR10`).
*   `loss_function`: Loss function for Stage 1 and 2 (`L2Loss`, `LPIPSHuberLoss`). Stage 3 always uses `L2Loss`.
*   `sampler`: Sampler for `t` values (`Uniform`, `U-shape`).
*   `model_name`: Neural network architecture (`Unet`, `MobileResUNet`).
*   `experiment_id`: Unique identifier for the current experiment.
*   `device`: `cuda` or `cpu`.
*   `image_size`, `batch_size`, `dropout_rate`, `ema_decay`.
*   `epochs_stage1`, `epochs_stage2`, `epochs_stage3`: Number of epochs for each stage.
*   `lr_stage1`, `lr_stage2`, `lr_stage3`: Learning rates for each stage.
*   `reflow_num_images`, `distillation_num_images`: Number of images to generate for subsequent stages.
*   `calculate_fid`: Whether to calculate FID during training.
*   `load_model_path`: Path to a pre-trained model to load.
